#!/bin/bash

echo "ğŸš€ Setting up Ollama with Mistral 7B model..."

# Check if running in Docker or locally
if command -v docker &> /dev/null && docker ps | grep -q call-analytics-ollama; then
    echo "ğŸ“¦ Detected Docker setup"
    OLLAMA_CMD="docker exec call-analytics-ollama ollama"
    API_URL="http://localhost:11434"
elif command -v ollama &> /dev/null; then
    echo "ğŸ’» Detected local Ollama installation"
    OLLAMA_CMD="ollama"
    API_URL="http://localhost:11434"
else
    echo "âŒ Ollama not found. Please install Ollama first:"
    echo "   curl -fsSL https://ollama.ai/install.sh | sh"
    exit 1
fi

# Wait for Ollama service to be ready
echo "â³ Waiting for Ollama service to start..."
max_attempts=30
attempt=1

while [ $attempt -le $max_attempts ]; do
    if curl -s $API_URL/api/tags > /dev/null 2>&1; then
        echo "âœ… Ollama service is ready!"
        break
    fi
    echo -n "."
    sleep 2
    attempt=$((attempt + 1))
done

if [ $attempt -gt $max_attempts ]; then
    echo "âŒ Ollama service failed to start after 60 seconds"
    exit 1
fi

# Check current models
echo "ğŸ“‹ Checking current models..."
$OLLAMA_CMD list

# Pull Mistral 7B model if not already available
echo "ğŸ“¥ Pulling Mistral 7B model (this may take a while)..."
if $OLLAMA_CMD list | grep -q "mistral:7b"; then
    echo "âœ… Mistral 7B already available"
else
    echo "â¬‡ï¸  Downloading Mistral 7B..."
    $OLLAMA_CMD pull mistral:7b
    
    if [ $? -eq 0 ]; then
        echo "âœ… Mistral 7B downloaded successfully"
    else
        echo "âŒ Failed to download Mistral 7B"
        exit 1
    fi
fi

# Test the model
echo "ğŸ§ª Testing Mistral 7B model..."
test_response=$($OLLAMA_CMD run mistral:7b "Hello, please respond with 'Test successful'" --verbose 2>/dev/null)

if echo "$test_response" | grep -q -i "test successful"; then
    echo "âœ… Model test successful"
else
    echo "âš ï¸  Model test response: $test_response"
fi

# Show final status
echo "ğŸ“Š Final model list:"
$OLLAMA_CMD list

# Performance tips
echo ""
echo "ğŸ¯ Performance Tips:"
echo "   â€¢ GPU: Make sure CUDA is available for better performance"
echo "   â€¢ Memory: Mistral 7B requires ~8GB RAM"
echo "   â€¢ For production: Consider using 'mistral:7b-instruct' for better instruction following"

# Test API endpoint
echo ""
echo "ğŸŒ Testing API endpoint..."
if curl -s -X POST $API_URL/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model":"mistral:7b","prompt":"Say hello in Hebrew","stream":false}' | grep -q "response"; then
    echo "âœ… API endpoint working correctly"
else
    echo "âš ï¸  API endpoint test failed"
fi

echo ""
echo "ğŸ‰ Ollama setup complete!"
echo "   â€¢ Model: Mistral 7B"
echo "   â€¢ API URL: $API_URL"
echo "   â€¢ Ready for Call Analytics processing"